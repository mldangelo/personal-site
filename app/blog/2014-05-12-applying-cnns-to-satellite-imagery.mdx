---
title: "Applying CNNs to Satellite Imagery: A New Frontier"
date: "2014-05-12"
summary: "The final project for CS231n is where theory meets practice. My goal is to apply the power of Convolutional Neural Networks to the unique challenges of satellite imagery. It's a different beast than the clean, well-defined images of ImageNet."
tags: ["cs231n", "deep learning", "planet labs", "computer vision", "satellite imagery", "project"]
category: "Technology"
readTime: 3
period: "Stanford"
---

The final project for CS231n is the ultimate test: take the concepts we've learned and apply them to a real-world problem. For me, the choice was obvious. I wanted to see if I could use CNNs to analyze the satellite imagery we're collecting at Planet.

This is a fascinating and challenging new frontier for computer vision. Most of the benchmark datasets, like ImageNet, are composed of pictures of everyday objects: cats, dogs, cars, etc. The images are generally well-lit, well-framed, and centered on the object of interest.

Satellite imagery is a whole different world. Instead of a single object, you have a complex scene with dozens of features. You have to contend with atmospheric haze, cloud cover, and different lighting conditions. A "car" isn't a clear, side-on view; it's a tiny blob of pixels seen from directly above.

My project is focused on a specific task: can I train a CNN to detect and classify different types of land use from our imagery? Can it learn to distinguish between a forest, a farm, a city, and a river?

This requires a different approach to network architecture and data augmentation. I'm experimenting with different ways to handle the multi-spectral data from our satellites and to make the model robust to the wide variety of conditions it will encounter. It's a challenging project, but it's also a glimpse into the future of how we'll understand our planet at scale.
